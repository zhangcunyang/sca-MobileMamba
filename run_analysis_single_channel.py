# ä½¿ç”¨ç°æœ‰å•é€šé“æ¨¡å‹è¿›è¡Œå¢å¼ºåˆ†æ
import os, time, torch, h5py, numpy as np
import torch.nn as nn
from torch.utils.data import DataLoader
import matplotlib; matplotlib.use("Agg")
import matplotlib.pyplot as plt

# ====== é¡¹ç›®å†…éƒ¨ ======
from ascad_loader_fixed import load_ascad_fixed_key
from trace_dataset_highorder import TraceDatasetHighOrder as TraceDataset
from mobile_mamba import MobileMambaSCA
from evaluate import evaluate, evaluate_per_class, evaluate_guessing_entropy
from enhanced_evaluate import EnhancedEvaluator

# ---------- é…ç½® ----------
TARGET_BYTE  = 0
WINDOW       = (6471, 7271)   # æ¥è‡ªé«˜é˜¶ SNR æ‰«æ
BATCH_SIZE   = 128
LOG_DIR      = "logs_enhanced"
EXISTING_MODEL_PATH = "checkpoints/mamba_model.pth"  # ä½¿ç”¨ç°æœ‰çš„å•é€šé“æ¨¡å‹
ANALYSIS_DIR = "analysis_results"

# åˆ›å»ºç›®å½•
os.makedirs(LOG_DIR, exist_ok=True)
os.makedirs(ANALYSIS_DIR, exist_ok=True)

print("=" * 60)
print("ä½¿ç”¨ç°æœ‰å•é€šé“æ¨¡å‹è¿›è¡Œå¢å¼ºåˆ†æ")
print("=" * 60)

# ---------- æ•°æ®åŠ è½½ ----------
print("åŠ è½½ASCADæ•°æ®é›†...")
(train_X, train_Y), (test_X, test_Y) = load_ascad_fixed_key(
    window=WINDOW, target_byte=TARGET_BYTE)

print(f"è®­ç»ƒé›†: {train_X.shape}, æµ‹è¯•é›†: {test_X.shape}")

# åˆ›å»ºå•é€šé“æ•°æ®é›†ï¼ˆä½¿ç”¨åŸå§‹çš„ä¸€é˜¶ç‰¹å¾ï¼‰
class SingleChannelDataset:
    """å•é€šé“æ•°æ®é›†ï¼Œç”¨äºå…¼å®¹ç°æœ‰æ¨¡å‹"""
    def __init__(self, traces, labels, normalize=True, training=False, noise_std=0.0):
        self.X = np.array(traces, dtype=np.float32)
        self.Y = np.array(labels, dtype=np.int64)
        self.training = training
        self.noise_std = noise_std
        
        # å…¨å±€ z-score æ ‡å‡†åŒ–
        if normalize:
            Î¼, Ïƒ = self.X.mean(), self.X.std()
            Ïƒ = Ïƒ if Ïƒ > 1e-6 else 1.0
            self.X = (self.X - Î¼) / Ïƒ
        
        # è½¬æ¢ä¸ºå•é€šé“æ ¼å¼ (N, 1, T)
        self.X = torch.from_numpy(self.X).unsqueeze(1)  # (N, 1, T)
        self.Y = torch.from_numpy(self.Y)
    
    def __len__(self):
        return len(self.X)
    
    def __getitem__(self, idx):
        x, y = self.X[idx], self.Y[idx]
        if self.training and self.noise_std > 0:
            noise = torch.randn_like(x) * self.noise_std
            x = x + noise
        return x, y

# åˆ›å»ºå•é€šé“æµ‹è¯•æ•°æ®é›†
test_ds = SingleChannelDataset(test_X, test_Y, normalize=True, training=False)
test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE)

# ---------- æ¨¡å‹åŠ è½½ ----------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# åˆ›å»ºå•é€šé“æ¨¡å‹ï¼ˆå¸¦biasä»¥å…¼å®¹ç°æœ‰æ¨¡å‹ï¼‰
class CompatibleMobileMambaSCA(MobileMambaSCA):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # æ·»åŠ biasä»¥å…¼å®¹ç°æœ‰æ¨¡å‹
        self.embed_33 = nn.Conv1d(1, 64, kernel_size=33, padding=16, stride=2, bias=True)
        self.embed_51 = nn.Conv1d(1, 64, kernel_size=51, padding=25, stride=2, bias=True)

model = CompatibleMobileMambaSCA(input_len=train_X.shape[1],
                                in_ch=1,          # å•é€šé“
                                dim=128,
                                num_blocks=6).to(device)

# åŠ è½½ç°æœ‰æ¨¡å‹
if os.path.exists(EXISTING_MODEL_PATH):
    print(f"åŠ è½½ç°æœ‰æ¨¡å‹: {EXISTING_MODEL_PATH}")
    model.load_state_dict(torch.load(EXISTING_MODEL_PATH, map_location=device))
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
else:
    print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: {EXISTING_MODEL_PATH}")
    exit(1)

print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

# ---------- åŸºç¡€è¯„ä¼° ----------
print("\n" + "=" * 40)
print("åŸºç¡€è¯„ä¼°")
print("=" * 40)

# æµ‹è¯•å‡†ç¡®ç‡
print("è®¡ç®—æµ‹è¯•å‡†ç¡®ç‡...")
test_acc = evaluate(model, test_dl, device)
print(f"æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")

# æ¯ç±»åˆ«åˆ†ç±»æŠ¥å‘Š
print("ç”Ÿæˆæ¯ç±»åˆ«åˆ†ç±»æŠ¥å‘Š...")
_ = evaluate_per_class(model, test_dl, device)

# ---------- å¢å¼ºåˆ†æ ----------
print("\n" + "=" * 40)
print("å¢å¼ºåˆ†æ - çŒœæµ‹ç†µå’Œt-SNEå¯è§†åŒ–")
print("=" * 40)

# å‡†å¤‡æ”»å‡»æ•°æ®
ATT_NUM = 2000  # æ”»å‡»æ ·æœ¬æ•°é‡
attack_ds = SingleChannelDataset(test_X[:ATT_NUM], test_Y[:ATT_NUM],
                                normalize=True, training=False)
attack_dl = DataLoader(attack_ds, batch_size=64)

# è·å–æ˜æ–‡å’ŒçœŸå®å¯†é’¥
with h5py.File("./datasets/raw/ASCAD_fixed_key.h5", "r") as f:
    pts   = f["metadata"][50000:50000+ATT_NUM]["plaintext"][:, TARGET_BYTE]
    trueK = int(f["metadata"][50000]["key"][TARGET_BYTE])

print(f"çœŸå®å¯†é’¥å­—èŠ‚ {TARGET_BYTE}: {trueK}")
print(f"æ”»å‡»æ ·æœ¬æ•°é‡: {ATT_NUM}")

# åˆ›å»ºå¢å¼ºè¯„ä¼°å™¨
evaluator = EnhancedEvaluator(model, device, num_classes=256)

# æ‰§è¡Œç»¼åˆåˆ†æ
print("å¼€å§‹ç»¼åˆåˆ†æ...")
class_ge, poor_classes = evaluator.comprehensive_analysis(
    attack_dl, pts, trueK, 
    target_byte=TARGET_BYTE, 
    max_traces=ATT_NUM,
    ge_threshold=30,  # çŒœæµ‹ç†µé˜ˆå€¼
    save_dir=ANALYSIS_DIR
)

# ---------- è¯¦ç»†åˆ†ææŠ¥å‘Š ----------
print("\n" + "=" * 40)
print("è¯¦ç»†åˆ†ææŠ¥å‘Š")
print("=" * 40)

print(f"æ€»å…±åˆ†æäº† {len(class_ge)} ä¸ªç±»åˆ«")
print(f"å‘ç° {len(poor_classes)} ä¸ªåˆ†ä¸å‡ºæ¥çš„ç±»åˆ«")

if poor_classes:
    print("\næœ€å·®çš„10ä¸ªç±»åˆ«:")
    for i, (class_id, ge) in enumerate(poor_classes[:10]):
        print(f"  {i+1:2d}. ç±»åˆ« {class_id:3d}: å¹³å‡çŒœæµ‹ç†µ = {ge:6.2f}")

# è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
ge_values = list(class_ge.values())
print(f"\nçŒœæµ‹ç†µç»Ÿè®¡:")
print(f"  æœ€å°å€¼: {min(ge_values):.2f}")
print(f"  æœ€å¤§å€¼: {max(ge_values):.2f}")
print(f"  å¹³å‡å€¼: {np.mean(ge_values):.2f}")
print(f"  ä¸­ä½æ•°: {np.median(ge_values):.2f}")
print(f"  æ ‡å‡†å·®: {np.std(ge_values):.2f}")

# ç»˜åˆ¶çŒœæµ‹ç†µåˆ†å¸ƒ
plt.figure(figsize=(10, 6))
plt.hist(ge_values, bins=30, alpha=0.7, edgecolor='black')
plt.axvline(np.mean(ge_values), color='red', linestyle='--', 
           label=f'å¹³å‡å€¼: {np.mean(ge_values):.2f}')
plt.axvline(np.median(ge_values), color='green', linestyle='--', 
           label=f'ä¸­ä½æ•°: {np.median(ge_values):.2f}')
plt.xlabel('çŒœæµ‹ç†µ')
plt.ylabel('ç±»åˆ«æ•°é‡')
plt.title('ç±»åˆ«çŒœæµ‹ç†µåˆ†å¸ƒ (å•é€šé“æ¨¡å‹)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig(f"{ANALYSIS_DIR}/ge_distribution_single_channel.png", dpi=300, bbox_inches='tight')
plt.close()

# ---------- ä¼ ç»ŸçŒœæµ‹ç†µæ›²çº¿ ----------
print("\nè®¡ç®—ä¼ ç»ŸçŒœæµ‹ç†µæ›²çº¿...")
ge_curve = evaluate_guessing_entropy(model, attack_dl, pts, trueK,
                                     device, max_traces=ATT_NUM)

plt.figure(figsize=(8, 5))
plt.plot(ge_curve, marker="o", markersize=2, linewidth=1)
plt.grid(True, alpha=0.3)
plt.title(f"ä¼ ç»ŸçŒœæµ‹ç†µæ›²çº¿ (å­—èŠ‚ {TARGET_BYTE}, å•é€šé“)")
plt.xlabel("æ”»å‡»è½¨è¿¹æ•°é‡")
plt.ylabel("çŒœæµ‹ç†µ")
plt.tight_layout()
plt.savefig(f"{LOG_DIR}/traditional_ge_curve_single_channel.png", dpi=300, bbox_inches='tight')
plt.close()

print(f"æœ€ç»ˆçŒœæµ‹ç†µ: {ge_curve[-1] if ge_curve else 'N/A'}")

# ---------- æ€»ç»“ ----------
print("\n" + "=" * 60)
print("åˆ†æå®Œæˆæ€»ç»“")
print("=" * 60)
print(f"âœ… ä½¿ç”¨ç°æœ‰å•é€šé“æ¨¡å‹: {EXISTING_MODEL_PATH}")
print(f"âœ… æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")
print(f"âœ… åˆ†æç»“æœä¿å­˜åœ¨: {ANALYSIS_DIR}/")
print(f"âœ… å‘ç° {len(poor_classes)} ä¸ªåˆ†ä¸å‡ºæ¥çš„ç±»åˆ«")
if ge_curve:
    print(f"âœ… ä¼ ç»ŸçŒœæµ‹ç†µ: {ge_curve[-1]}")
print("\nç”Ÿæˆçš„æ–‡ä»¶:")
print(f"  - {LOG_DIR}/traditional_ge_curve_single_channel.png (ä¼ ç»ŸçŒœæµ‹ç†µæ›²çº¿)")
print(f"  - {ANALYSIS_DIR}/class_guessing_entropy.png (ç±»åˆ«çŒœæµ‹ç†µ)")
print(f"  - {ANALYSIS_DIR}/ge_distribution_single_channel.png (çŒœæµ‹ç†µåˆ†å¸ƒ)")
print(f"  - {ANALYSIS_DIR}/tsne_worst_classes.png (t-SNEå¯è§†åŒ–)")
print(f"  - {ANALYSIS_DIR}/class_analysis_results.csv (è¯¦ç»†ç»“æœ)")

print("\nğŸ‰ ä½¿ç”¨ç°æœ‰å•é€šé“æ¨¡å‹çš„åˆ†æå®Œæˆï¼")
